"""
Background Jobs & Task Scheduling - APScheduler Setup
Aliaport v3.1 - FAZ 5 (Performance & Scalability)
"""

from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.jobstores.sqlalchemy import SQLAlchemyJobStore
from apscheduler.executors.pool import ThreadPoolExecutor, ProcessPoolExecutor
from datetime import datetime
import logging
import os

logger = logging.getLogger(__name__)

# Database URL (PostgreSQL iÃ§in job persistence)
DATABASE_URL = os.getenv(
    "DATABASE_URL", 
    "sqlite:///./aliaport.db"  # Development fallback
)

# Job stores (PostgreSQL'de job metadata sakla)
jobstores = {
    'default': SQLAlchemyJobStore(url=DATABASE_URL)
}

# Executors (thread ve process pool)
executors = {
    'default': ThreadPoolExecutor(max_workers=5),
    'processpool': ProcessPoolExecutor(max_workers=3)
}

# Job defaults (global ayarlar)
job_defaults = {
    'coalesce': True,  # Birden fazla missed run varsa tek seferde Ã§alÄ±ÅŸtÄ±r
    'max_instances': 1,  # AynÄ± job'dan sadece 1 instance Ã§alÄ±ÅŸsÄ±n (overlap prevention)
    'misfire_grace_time': 300  # 5 dakika geÃ§ baÅŸlama toleransÄ±
}

# Scheduler instance (AsyncIO - FastAPI ile uyumlu)
scheduler = AsyncIOScheduler(
    jobstores=jobstores,
    executors=executors,
    job_defaults=job_defaults,
    timezone='Europe/Istanbul'  # TÃ¼rkiye saati
)


def start_scheduler():
    """
    Scheduler'Ä± baÅŸlat
    
    FastAPI startup event'inde Ã§aÄŸrÄ±lÄ±r.
    """
    if not scheduler.running:
        scheduler.start()
        logger.info("âœ… APScheduler started successfully")
        
        # Mevcut job'larÄ± logla
        jobs = scheduler.get_jobs()
        if jobs:
            logger.info(f"ğŸ“‹ Registered jobs ({len(jobs)}):")
            for job in jobs:
                logger.info(f"  - {job.id}: {job.name} (next run: {job.next_run_time})")
        else:
            logger.warning("âš ï¸  No jobs registered yet")
    else:
        logger.warning("âš ï¸  APScheduler already running")


def shutdown_scheduler():
    """
    Scheduler'Ä± gracefully durdur
    
    FastAPI shutdown event'inde Ã§aÄŸrÄ±lÄ±r.
    Running job'larÄ±n tamamlanmasÄ±nÄ± bekler.
    """
    if scheduler.running:
        logger.info("ğŸ›‘ Shutting down APScheduler...")
        scheduler.shutdown(wait=True)  # wait=True: Running job'larÄ± bekle
        logger.info("âœ… APScheduler shutdown complete")
    else:
        logger.warning("âš ï¸  APScheduler not running")


def get_scheduler_info():
    """
    Scheduler durumu ve job listesi
    
    Returns:
        dict: Scheduler metadata
    """
    jobs = scheduler.get_jobs()
    
    job_list = []
    for job in jobs:
        job_list.append({
            "id": job.id,
            "name": job.name,
            "trigger": str(job.trigger),
            "next_run_time": job.next_run_time.isoformat() if job.next_run_time else None,
            "max_instances": job.max_instances,
            "coalesce": job.coalesce
        })
    
    return {
        "running": scheduler.running,
        "state": scheduler.state,
        "timezone": str(scheduler.timezone),
        "jobs_count": len(jobs),
        "jobs": job_list
    }


def pause_job(job_id: str):
    """Job'Ä± geÃ§ici olarak durdur"""
    scheduler.pause_job(job_id)
    logger.info(f"â¸ï¸  Job paused: {job_id}")


def resume_job(job_id: str):
    """DurdurulmuÅŸ job'Ä± devam ettir"""
    scheduler.resume_job(job_id)
    logger.info(f"â–¶ï¸  Job resumed: {job_id}")


def remove_job(job_id: str):
    """Job'Ä± tamamen kaldÄ±r"""
    scheduler.remove_job(job_id)
    logger.info(f"ğŸ—‘ï¸  Job removed: {job_id}")


def run_job_now(job_id: str):
    """Job'Ä± hemen Ã§alÄ±ÅŸtÄ±r (zamanlanmÄ±ÅŸ run'dan baÄŸÄ±msÄ±z)"""
    job = scheduler.get_job(job_id)
    if job:
        job.modify(next_run_time=datetime.now())
        logger.info(f"ğŸš€ Job triggered manually: {job_id}")
    else:
        logger.error(f"âŒ Job not found: {job_id}")
